{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82f61233-3de2-459a-84b0-1784e738a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0f9b40c-0c39-41a9-a952-1186d3364a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns:\n",
      "['Customer', 'Generator Capacity', 'Postcode', 'Consumption Category', 'date', '0:30', '1:00', '1:30', '2:00', '2:30', '3:00', '3:30', '4:00', '4:30', '5:00', '5:30', '6:00', '6:30', '7:00', '7:30', '8:00', '8:30', '9:00', '9:30', '10:00', '10:30', '11:00', '11:30', '12:00', '12:30', '13:00', '13:30', '14:00', '14:30', '15:00', '15:30', '16:00', '16:30', '17:00', '17:30', '18:00', '18:30', '19:00', '19:30', '20:00', '20:30', '21:00', '21:30', '22:00', '22:30', '23:00', '23:30', '0:00']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Customer                  int64\n",
       "Generator Capacity      float64\n",
       "Postcode                  int64\n",
       "Consumption Category     object\n",
       "date                     object\n",
       "0:30                    float64\n",
       "1:00                    float64\n",
       "1:30                    float64\n",
       "2:00                    float64\n",
       "2:30                    float64\n",
       "3:00                    float64\n",
       "3:30                    float64\n",
       "4:00                    float64\n",
       "4:30                    float64\n",
       "5:00                    float64\n",
       "5:30                    float64\n",
       "6:00                    float64\n",
       "6:30                    float64\n",
       "7:00                    float64\n",
       "7:30                    float64\n",
       "8:00                    float64\n",
       "8:30                    float64\n",
       "9:00                    float64\n",
       "9:30                    float64\n",
       "10:00                   float64\n",
       "10:30                   float64\n",
       "11:00                   float64\n",
       "11:30                   float64\n",
       "12:00                   float64\n",
       "12:30                   float64\n",
       "13:00                   float64\n",
       "13:30                   float64\n",
       "14:00                   float64\n",
       "14:30                   float64\n",
       "15:00                   float64\n",
       "15:30                   float64\n",
       "16:00                   float64\n",
       "16:30                   float64\n",
       "17:00                   float64\n",
       "17:30                   float64\n",
       "18:00                   float64\n",
       "18:30                   float64\n",
       "19:00                   float64\n",
       "19:30                   float64\n",
       "20:00                   float64\n",
       "20:30                   float64\n",
       "21:00                   float64\n",
       "21:30                   float64\n",
       "22:00                   float64\n",
       "22:30                   float64\n",
       "23:00                   float64\n",
       "23:30                   float64\n",
       "0:00                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to do a simple test to check the dataset columns and corresponding data types\n",
    "df = pd.read_csv('2010-2011 Solar home electricity data.csv', skiprows=1, header=0, low_memory=False)\n",
    "print(\"\\nColumns:\")\n",
    "print(df.columns.tolist())\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69101095-af88-4800-9d51-1acf6d547e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer', 'Generator Capacity', 'Postcode', 'Consumption Category',\n",
       "       'date', '0:30', '1:00', '1:30', '2:00', '2:30', '3:00', '3:30', '4:00',\n",
       "       '4:30', '5:00', '5:30', '6:00', '6:30', '7:00', '7:30', '8:00', '8:30',\n",
       "       '9:00', '9:30', '10:00', '10:30', '11:00', '11:30', '12:00', '12:30',\n",
       "       '13:00', '13:30', '14:00', '14:30', '15:00', '15:30', '16:00', '16:30',\n",
       "       '17:00', '17:30', '18:00', '18:30', '19:00', '19:30', '20:00', '20:30',\n",
       "       '21:00', '21:30', '22:00', '22:30', '23:00', '23:30', '0:00'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d763bab9-64e8-43b3-9c63-63f533d2821c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer</th>\n",
       "      <th>Generator Capacity</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Consumption Category</th>\n",
       "      <th>date</th>\n",
       "      <th>0:30</th>\n",
       "      <th>1:00</th>\n",
       "      <th>1:30</th>\n",
       "      <th>2:00</th>\n",
       "      <th>2:30</th>\n",
       "      <th>...</th>\n",
       "      <th>19:30</th>\n",
       "      <th>20:00</th>\n",
       "      <th>20:30</th>\n",
       "      <th>21:00</th>\n",
       "      <th>21:30</th>\n",
       "      <th>22:00</th>\n",
       "      <th>22:30</th>\n",
       "      <th>23:00</th>\n",
       "      <th>23:30</th>\n",
       "      <th>0:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2076</td>\n",
       "      <td>GC</td>\n",
       "      <td>1-Jul-10</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2076</td>\n",
       "      <td>CL</td>\n",
       "      <td>1-Jul-10</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.244</td>\n",
       "      <td>1.256</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2076</td>\n",
       "      <td>GG</td>\n",
       "      <td>1-Jul-10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2076</td>\n",
       "      <td>GC</td>\n",
       "      <td>2-Jul-10</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.012</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2076</td>\n",
       "      <td>CL</td>\n",
       "      <td>2-Jul-10</td>\n",
       "      <td>1.238</td>\n",
       "      <td>1.238</td>\n",
       "      <td>1.256</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer  Generator Capacity  Postcode Consumption Category      date  \\\n",
       "0         1                3.78      2076                   GC  1-Jul-10   \n",
       "1         1                3.78      2076                   CL  1-Jul-10   \n",
       "2         1                3.78      2076                   GG  1-Jul-10   \n",
       "3         1                3.78      2076                   GC  2-Jul-10   \n",
       "4         1                3.78      2076                   CL  2-Jul-10   \n",
       "\n",
       "    0:30   1:00   1:30   2:00   2:30  ...  19:30  20:00  20:30  21:00  21:30  \\\n",
       "0  0.303  0.471  0.083  0.121  0.361  ...  0.495   0.54  0.406  0.543  0.495   \n",
       "1  1.250  1.244  1.256  0.744  0.019  ...  0.000   0.00  0.000  0.000  0.000   \n",
       "2  0.000  0.000  0.000  0.000  0.000  ...  0.000   0.00  0.000  0.000  0.000   \n",
       "3  0.116  0.346  0.122  0.079  0.120  ...  0.262   1.10  1.012  0.817  0.526   \n",
       "4  1.238  1.238  1.256  1.250  0.169  ...  0.000   0.00  0.000  0.000  0.000   \n",
       "\n",
       "   22:00  22:30  23:00  23:30   0:00  \n",
       "0  0.216  0.378  0.128  0.078  0.125  \n",
       "1  0.000  0.000  0.000  0.000  1.075  \n",
       "2  0.000  0.000  0.000  0.000  0.000  \n",
       "3  0.335  0.402  0.142  0.120  0.111  \n",
       "4  0.000  0.000  0.000  0.000  1.088  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d50cdf3d-5223-435b-8048-74ae6693f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6e756af-5ece-416d-b1e7-c5ff5995975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_solar_file(file_path):\n",
    "    \"\"\"\n",
    "    filter customer based on CL values and do date data format change\n",
    "    \"\"\"\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(file_path, \n",
    "                        skiprows=1,\n",
    "                        header=0,\n",
    "                        low_memory=False)\n",
    "        \n",
    "    print(f\"\\nProcessing {file_path}\")\n",
    "\n",
    "    # get time columns\n",
    "    time_cols = [col for col in df.columns if ':' in str(col)]\n",
    "        \n",
    "     \n",
    "    # Find customers that have any CL > 0\n",
    "    cl_mask = (df['Consumption Category'] == 'CL') & (df[time_cols] > 0).any(axis=1)\n",
    "    customers_with_cl = df[cl_mask]['Customer'].unique()\n",
    "    \n",
    "    # Remove customers with CL > 0 and keep only GG/GC categories\n",
    "    df = df[\n",
    "        (~df['Customer'].isin(customers_with_cl)) & \n",
    "        (df['Consumption Category'].isin(['GG', 'GC']))\n",
    "    ].copy()\n",
    "    \n",
    "    \n",
    "    print(f\"Number of customers removed due to positive CL values: {len(customers_with_cl)}\")\n",
    "        \n",
    "    # convert date based on file year\n",
    "    if '2010-2011' in file_path:\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%d-%b-%y')\n",
    "    else:\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y')\n",
    "\n",
    "\n",
    "    # filter out rows where GG/GC values are all zero\n",
    "    df = df[df[time_cols].sum(axis=1) > 0]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a205e61-d361-4e93-adf0-9fdf601895a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_daily_dataset(df):\n",
    "    \"\"\"\n",
    "    create daily dataset with GG and GC values and corresponding date and net load\n",
    "    \"\"\"\n",
    "    # get time columns\n",
    "    time_cols = [col for col in df.columns if ':' in str(col)]\n",
    "    \n",
    "    # takes the first (and only) row of each group and then sums across all the time columns to get the daily total\n",
    "    daily_sums = df.groupby(['Customer', 'Postcode', 'date', 'Consumption Category'])[time_cols].first().sum(axis=1).reset_index()\n",
    "    \n",
    "    # create the pivot table\n",
    "    daily_data = daily_sums.pivot(\n",
    "        index=['Customer', 'Postcode', 'date'],\n",
    "        columns='Consumption Category',\n",
    "        values=0\n",
    "    ).reset_index()\n",
    "    \n",
    "    # In case any NaN values exist after the pivot operation, fill Nah with 0\n",
    "    # and then we calculate the net load\n",
    "    daily_data = daily_data.fillna(0)\n",
    "    daily_data['net_load'] = daily_data['GC'] - daily_data['GG']\n",
    "\n",
    "    daily_data.to_csv('prosumer_daily_data1.csv',\n",
    "                     index=False,\n",
    "                     sep=',',\n",
    "                     date_format='%Y-%m-%d',\n",
    "                     encoding='utf-8')\n",
    "    \n",
    "    return daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7468d89c-3c20-4fe8-9b56-7b00e95c7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hourly_dataset(df):\n",
    "    \"\"\"\n",
    "    create hourly dataset with GG and GC values and corresponding date and net load\n",
    "    \"\"\"\n",
    "    # get time columns\n",
    "    time_cols = [col for col in df.columns if ':' in str(col)]\n",
    "\n",
    "    # Custom sorting function for time columns\n",
    "    def time_to_minutes(time_str):\n",
    "        # Handle the special case of '0:00' which should be last\n",
    "        if time_str == '0:00':\n",
    "            return 24 * 60\n",
    "        hours, minutes = map(int, time_str.split(':'))\n",
    "        return hours * 60 + minutes\n",
    "    \n",
    "    time_cols.sort(key=time_to_minutes)\n",
    "    \n",
    "    # melt to get hourly values\n",
    "    melted = pd.melt(\n",
    "        df,\n",
    "        id_vars=['Customer', 'Postcode', 'date', 'Consumption Category'],\n",
    "        value_vars=time_cols,  # convert from columns(half-hour time interval) to rows\n",
    "        var_name='hour',       # new column name which contains the old column names\n",
    "        value_name='value'     # new column name which contains the values\n",
    "    )\n",
    "    \n",
    "    # create pivot table\n",
    "    hourly_data = melted.pivot_table(\n",
    "        index=['Customer', 'Postcode', 'date', 'hour'],\n",
    "        columns='Consumption Category',\n",
    "        values='value',\n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "    \n",
    "    # add net load\n",
    "    hourly_data['net_load'] = hourly_data['GC'] - hourly_data['GG']\n",
    "\n",
    "    # Sort by Customer, date, and hour\n",
    "    hourly_data = hourly_data.sort_values(['Customer', 'date', 'hour'], \n",
    "                                        key=lambda x: x if x.name != 'hour' \n",
    "                                        else pd.Series([time_to_minutes(t) for t in x]))\n",
    "\n",
    "    hourly_data.to_csv('prosumer_hourly_data1.csv',\n",
    "                      index=False,\n",
    "                      sep=',',\n",
    "                      date_format='%Y-%m-%d',\n",
    "                      encoding='utf-8')\n",
    "    \n",
    "    return hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02cd9c55-0447-479f-bec0-7c6e58d9a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2010-2011 Solar home electricity data.csv\n",
      "Number of customers removed due to positive CL values: 136\n",
      "Successfully processed 2010-2011 Solar home electricity data.csv\n",
      "\n",
      "Processing 2011-2012 Solar home electricity data v2.csv\n",
      "Number of customers removed due to positive CL values: 136\n",
      "Successfully processed 2011-2012 Solar home electricity data v2.csv\n",
      "\n",
      "Processing 2012-2013 Solar home electricity data v2.csv\n",
      "Number of customers removed due to positive CL values: 135\n",
      "Successfully processed 2012-2013 Solar home electricity data v2.csv\n",
      "\n",
      "Combining all data...\n",
      "\n",
      "Creating daily dataset...\n",
      "\n",
      "Creating hourly dataset...\n",
      "\n",
      "Final Summary:\n",
      "Number of unique customers: 166\n",
      "Date range: 2010-07-01 00:00:00 to 2013-06-30 00:00:00\n",
      "\n",
      "Daily data columns: ['Customer', 'Postcode', 'date', 'GC', 'GG', 'net_load']\n",
      "Hourly data columns: ['Customer', 'Postcode', 'date', 'hour', 'GC', 'GG', 'net_load']\n"
     ]
    }
   ],
   "source": [
    "# dataset files to process\n",
    "files = [\n",
    "    '2010-2011 Solar home electricity data.csv',\n",
    "    '2011-2012 Solar home electricity data v2.csv',\n",
    "    '2012-2013 Solar home electricity data v2.csv'\n",
    "]\n",
    "\n",
    "# process all files\n",
    "all_data = []\n",
    "for file in files:\n",
    "    df = process_solar_file(file)\n",
    "    # check if we get valid data\n",
    "    if df is not None and not df.empty:\n",
    "        all_data.append(df)\n",
    "        print(f\"Successfully processed {file}\")\n",
    "\n",
    "if all_data:\n",
    "    print(\"\\nCombining all data...\")\n",
    "    # combine all years of data into one dataFrame\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    print(\"\\nCreating daily dataset...\")\n",
    "    daily_data = create_daily_dataset(combined_data)\n",
    "    \n",
    "    print(\"\\nCreating hourly dataset...\")\n",
    "    hourly_data = create_hourly_dataset(combined_data)\n",
    "    \n",
    "    print(\"\\nFinal Summary:\")\n",
    "    print(f\"Number of unique customers: {len(daily_data['Customer'].unique())}\")\n",
    "    print(f\"Date range: {daily_data['date'].min()} to {daily_data['date'].max()}\")\n",
    "    print(\"\\nDaily data columns:\", daily_data.columns.tolist())\n",
    "    print(\"Hourly data columns:\", hourly_data.columns.tolist())\n",
    "else:\n",
    "    print(\"\\nNo data was processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598c89e-06e6-45bb-bd62-073113e19472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9b883ff-7dbe-4e41-9c16-3b388970a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combining all data...\n",
      "\n",
      "Creating daily dataset...\n",
      "\n",
      "Creating hourly dataset...\n",
      "\n",
      "Final Summary:\n",
      "\n",
      "Daily dataset format:\n",
      "   User ID  Postcode       date  daily_gg  daily_gc\n",
      "0       11      2026 2010-07-01     6.743    26.873\n",
      "1       11      2026 2010-07-02     1.977    20.961\n",
      "2       11      2026 2010-07-03     7.305    37.023\n",
      "3       11      2026 2010-07-04     6.573    31.955\n",
      "4       11      2026 2010-07-05     1.378    34.751\n",
      "\n",
      "Hourly dataset format:\n",
      "    User ID  Postcode       date  hour  hourly_gc  hourly_gg\n",
      "1        11      2026 2010-07-01  0:30      0.118        0.0\n",
      "22       11      2026 2010-07-01  1:00      0.138        0.0\n",
      "23       11      2026 2010-07-01  1:30      0.118        0.0\n",
      "32       11      2026 2010-07-01  2:00      0.108        0.0\n",
      "33       11      2026 2010-07-01  2:30      0.096        0.0\n"
     ]
    }
   ],
   "source": [
    "# different data columns like User ID, postcode, daily gg daily gc / User ID, postcode, hourly gg hourly gc\n",
    "# data column formats required by fusen shixiong\n",
    "# almost same as the before functions\n",
    "def create_daily_dataset(df):\n",
    "    \"\"\"\n",
    "    create daily dataset with format:\n",
    "    User ID, postcode, daily GG, daily GC\n",
    "    \"\"\"\n",
    "    # get time columns\n",
    "    time_cols = [col for col in df.columns if ':' in str(col)]\n",
    "    \n",
    "    # calculate daily sums for GG and GC separately\n",
    "    daily_gg = df[df['Consumption Category'] == 'GG'].groupby(['Customer', 'Postcode', 'date'])[time_cols].sum().sum(axis=1).reset_index()\n",
    "    daily_gc = df[df['Consumption Category'] == 'GC'].groupby(['Customer', 'Postcode', 'date'])[time_cols].sum().sum(axis=1).reset_index()\n",
    "    \n",
    "    # merge GG and GC data\n",
    "    daily_data = daily_gg.merge(daily_gc, on=['Customer', 'Postcode', 'date'], suffixes=('_gg', '_gc'))\n",
    "    \n",
    "    # rename columns to match desired format\n",
    "    daily_data.columns = ['User ID', 'Postcode', 'date', 'daily_gg', 'daily_gc']\n",
    "    \n",
    "    # save with proper formatting\n",
    "    daily_data.to_csv('prosumer_daily_data2.csv',\n",
    "                     index=False,\n",
    "                     sep=',',\n",
    "                     #float_format='%.3f',\n",
    "                     encoding='utf-8')\n",
    "    \n",
    "    return daily_data\n",
    "\n",
    "def create_hourly_dataset(df):\n",
    "    \"\"\"\n",
    "    create hourly dataset with format:\n",
    "    User ID, postcode, hourly GG, hourly GC\n",
    "    \"\"\"\n",
    "    # get time columns\n",
    "    time_cols = [col for col in df.columns if ':' in str(col)]\n",
    "    \n",
    "    # melt the data to get hourly values\n",
    "    melted = pd.melt(\n",
    "        df,\n",
    "        id_vars=['Customer', 'Postcode', 'date', 'Consumption Category'],\n",
    "        value_vars=time_cols,\n",
    "        var_name='hour',\n",
    "        value_name='value'\n",
    "    )\n",
    "    \n",
    "    # pivot to get GG and GC in separate columns\n",
    "    hourly_data = melted.pivot_table(\n",
    "        index=['Customer', 'Postcode', 'date', 'hour'],\n",
    "        columns='Consumption Category',\n",
    "        values='value',\n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "    \n",
    "    # rename columns to match desired format\n",
    "    hourly_data.columns.name = None\n",
    "    hourly_data = hourly_data.rename(columns={\n",
    "        'Customer': 'User ID',\n",
    "        'Postcode': 'Postcode',\n",
    "        'GG': 'hourly_gg',\n",
    "        'GC': 'hourly_gc'\n",
    "    })\n",
    "    \n",
    "    # sort by time\n",
    "    def time_to_minutes(time_str):\n",
    "        if time_str == '0:00':\n",
    "            return 24 * 60\n",
    "        hours, minutes = map(int, time_str.split(':'))\n",
    "        return hours * 60 + minutes\n",
    "    \n",
    "    hourly_data = hourly_data.sort_values(\n",
    "        ['User ID', 'date', 'hour'],\n",
    "        key=lambda x: x if x.name != 'hour' else pd.Series([time_to_minutes(t) for t in x])\n",
    "    )\n",
    "    \n",
    "    # save with proper formatting\n",
    "    hourly_data.to_csv('prosumer_hourly_data2.csv',\n",
    "                      index=False,\n",
    "                      sep=',',\n",
    "                      #float_format='%.3f',\n",
    "                      encoding='utf-8')\n",
    "    \n",
    "    return hourly_data\n",
    "\n",
    "# when processing the data:\n",
    "if all_data:\n",
    "    print(\"\\nCombining all data...\")\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    print(\"\\nCreating daily dataset...\")\n",
    "    daily_data = create_daily_dataset(combined_data)\n",
    "    \n",
    "    print(\"\\nCreating hourly dataset...\")\n",
    "    hourly_data = create_hourly_dataset(combined_data)\n",
    "    \n",
    "    print(\"\\nFinal Summary:\")\n",
    "    print(\"\\nDaily dataset format:\")\n",
    "    print(daily_data.head())\n",
    "    print(\"\\nHourly dataset format:\")\n",
    "    print(hourly_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07769aa5-ac7f-4d70-9b05-7f0af355bb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925e023-802e-44e1-9ef9-7b3332ad491f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6ea2f-9064-4d53-bf89-4a52d7df3798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
